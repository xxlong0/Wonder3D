pretrained_model_name_or_path: 'lambdalabs/sd-image-variations-diffusers'
pretrained_unet_path: 'path_of_your_stage1_model'
revision: null
train_dataset:
  root_dir_ortho: 'datapath/ortho-13views'  # change to your path
  root_dir_persp: 'datapath/persp_13views' # change to your path
  pred_ortho: true
  pred_persp: true
  object_list: './datalist/datalist_single_obj.json'
  invalid_list: null
  num_views: 6
  groups_num: 1
  bg_color: 'three_choices'
  img_wh: [256, 256]
  validation: false
  num_validation_samples: 32
  read_normal: false
  read_color: true
  pred_type: 'mixed_rgb_noraml_mask'
  load_cam_type: true
  load_switcher: False
validation_dataset:
  root_dir_ortho: 'datapath/ortho-13views'  # change to your path
  root_dir_persp: 'datapath/persp_13views' # change to your path
  pred_ortho: true
  pred_persp: true
  object_list: './datalist/datalist_single_obj.json'
  invalid_list: null
  num_views: 6
  groups_num: 1
  bg_color: 'white'
  img_wh: [256, 256]
  validation: true
  num_validation_samples: 32
  read_normal: false
  read_color: true
  pred_type: 'mixed_rgb_noraml_mask'
  load_cam_type: true
  load_switcher: False
validation_train_dataset:
  root_dir_ortho: 'datapath/ortho-13views'  # change to your path
  root_dir_persp: 'datapath/persp_13views' # change to your path
  pred_ortho: true
  pred_persp: true
  object_list: './datalist/datalist_single_obj.json'
  invalid_list: null
  num_views: 6
  groups_num: 1
  bg_color: 'white'
  img_wh: [256, 256]
  validation: false
  num_validation_samples: 32
  num_samples: 32
  read_normal: false
  read_color: true
  pred_type: 'mixed_rgb_noraml_mask'
  load_cam_type: true
  load_switcher: False

pred_type: 'mixed_rgb_noraml_mask'

output_dir: 'outputs/stage2-train'
seed: 42
train_batch_size: 18
validation_batch_size: 8
validation_train_batch_size: 8
max_train_steps: 80000
gradient_accumulation_steps: 4
gradient_checkpointing: False
learning_rate: 1.e-4
scale_lr: false
lr_scheduler: "constant_with_warmup"
lr_warmup_steps: 100
snr_gamma: 5.0
use_8bit_adam: false
allow_tf32: true
use_ema: true
dataloader_num_workers: 16
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 1.e-2
adam_epsilon: 1.e-08
max_grad_norm: 1.0
prediction_type: null
vis_dir: vis
logging_dir: logs
mixed_precision: "fp16"
report_to: 'tensorboard'
local_rank: -1
checkpointing_steps: 5000
checkpoints_total_limit: 20
resume_from_checkpoint: latest
enable_xformers_memory_efficient_attention: false
validation_steps: 5000
validation_sanity_check: false
tracker_project_name: 'mvdiffusion-image-v1'

trainable_modules: null
use_classifier_free_guidance: true
condition_drop_rate: 0.05
drop_type: 'drop_as_a_whole'  # modify
camera_embedding_lr_mult: 10.
scale_input_latents: true

pipe_kwargs:
  camera_embedding_type: 'e_de_da_sincos'
  num_views: 6

validation_guidance_scales: [1., 3.]
pipe_validation_kwargs:
  eta: 1.0
validation_grid_nrow: 12

unet_from_pretrained_kwargs:
  camera_embedding_type: 'e_de_da_sincos'
  projection_class_embeddings_input_dim: 14  # modify
  num_views: 6
  sample_size: 32
  zero_init_conv_in: true
  zero_init_camera_projection: false
  cd_attention_last: false
  cd_attention_mid: false
  multiview_attention: true
  sparse_mv_attention: false
  mvcd_attention: false

num_views: 6
camera_embedding_type: 'e_de_da_sincos'
